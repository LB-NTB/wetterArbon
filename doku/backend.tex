\section{Serverseitige Implementierung und Datenbank-Architektur}
Die serverseitige Implementierung bildet die Schnittstelle zwischen dem Client das heisst dem Internet Browser und den Messdaten. Diese müssen von den Sensoren in regelmässigen Abständen abgerufen und in der Datenbank gespeichert werden. Da die Datenbank das Herzstück der Wetterstation darstellt muss sie auch entsprechend geschützt werden vor Datenverlust und oder -manipulation. Die einzelnen Komponenten sowie der Aufbau der Datenbank werden im Folgenden erläutert.

%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Datenerfassung}
Die einzelnen Daten werden unterschiedlich erfasst, wobei mit Ausnahme der Messwerten des Kombi-Wettertransmitters sämtliche Abfragen mittels Skripten durchgeführt werden. Ein Übersicht des Datenflusses ist in Abbildung\,\ref{img:datenerfassung} dargestellt. Im Folgenden werden die einzelnen Skripte erklärt.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/datenerfassung}}
	\centering
	\caption{Schematische Übersicht der Datenerfassung}
	\label{img:datenerfassung}
\end{figure}


\subsubsection{Erfassung der Messdaten des Kombi-Wettertransmitters}
Die Daten des Kombi-Wettertransmitters werden weiterhin von WeatherDisplay über eine virtuelle serielle Schnittstelle abgerufen, aufbereitet und im Minutentakt in die Datenbank gespeichert. Kann ein Datenbankeintrag aus irgendwelchen Gründen nicht erstellt werden, wird dies, wie später im Kapitel\,\ref{kap:Funktionsüberwachung} beschrieben, gemeldet. Weiter erzeugt Weather Display mehrere Text Files, welche unter anderem für die Aussenanzeige (Laufschrift am Hafengebäude) benötigt werden. Die Aussenanzeige ist aber nicht Bestandteil dieser Arbeit.

\subsubsection{Einlesen von Pegel-, Strahlungs, und Wassertemperaturmesswerten}
Strahlungs- und Pegelsensor sind an einem Web-IO angeschlossen (siehe Datenblatt im Anhang\,\ref{Spec_webio}), welches die analogen Werte (in Milliampere) per Web-Schnittstelle zur Verfügung stellt. Die Abfrage erfolgt einmal pro Minute durch ein Python-Skript, wie in Listing \ref{lst:webIo} dargestellt. Die Temperatursensoren (PT100-Elemente) werden ähnlich erfasst mit dem Unterschied, dass nicht der Widerstandswert sondern direkt Grad Celsius geliefert wird. Als Schnittstelle wird an Stelle des Web-IO ein Web-Thermograph eingesetzt (siehe Datenblatt im Anhang\,\ref{Spec_webthermograph}).

\begin{lstlisting}[label=lst:webIo,caption=Python-Script zur Web-Abfrage des Pegel-Messwerts, language=python, style=py]
try:
    buffer = StringIO()
    c = pycurl.Curl()
    c.setopt(c.URL, 'http://webcam.wetter-arbon.ch:50506/single1')
    c.setopt(c.WRITEDATA, buffer)
    c.perform()
    c.close()
    requestMeasurement = buffer.getvalue()
\end{lstlisting}

\noindent
Der URL-Request wird mittels cURL ausgeführt. Die Abfrage ist für alle genannten Sensoren die gleiche, mit Ausnahme der Portnummer, welche sich je nach Sensor unterscheidet. Die Abfragen sind nach dem try... catch - Prinzip aufgebaut, sodass das Skript weiterläuft auch wenn ein Web-Interface nicht antwortet.



\subsubsection{Abgreifen der Sturmwarndaten} % screen scrapping
Die Sturmwarndaten werden periodisch mittels Python-Skript ausgelesen. Als Tool kommt die Python-Bibliothek \href{https://www.crummy.com/software/BeautifulSoup/}{\emph{BeautifulSoup}} zum Einsatz. Das Auslesen von Webseiten wird auch \emph{web scraping} genannt. Die Idee dahinter ist, die gewünschte Information auf Grund ihrer Element-Bezeichnung (z.B. \texttt{<td>}), ihres Attributs (z.B. \texttt{class="titelfett"}) oder Hierarchistufe (z.B. \texttt{tr:nth-of-type(4)}) eindeutig zu identifizieren. Um diese eindeutige Identifikation herauszufinden wurde das Google Chrome-Plugin \href{https://selectorgadget.com/}{\emph{SelectorGadget }} verwendet. Listing \ref{lst:kttgCrawler} zeigt die gesamte Abfrage. Darin ist auch das Problem dieser Methode gut erkennbar. Ändert die URL oder die Bezeichnung bzw. Struktur der Seite, liefert das Skript nicht mehr die gewünschten Daten. Da aber das Web-Scrapping die einzige kostenlose Möglichkeit darstellt um die Daten zu erhalten, muss dieses Risiko akzeptiert werden.


\begin{lstlisting}[label=lst:kttgCrawler,caption=Web-Scrapper für die Sturmwarndaten, language=python, style=py]
page = requests.get('http://www.kttg.ch/kapo/htm/stwarn.shtml')
soup = BeautifulSoup(page.text, 'html.parser')
# Einschaltzeit auslesen
soup.select('table tr:nth-of-type(4) td'):
# Status auslesen
soup.select('.titelfett strong'):
\end{lstlisting}


\subsubsection{Windvorhersagedaten}
Die Abfrage der Datenban stellt sich als recht kompliziert heraus. Sodass entschieden wurde eine VIEW einzusetzten. Diese wird dynamisch bei Aufrufen erzeugt und enthält die gewünschten Daten. Der SQL-Befehl für die Erzeugung der VIEW ist vereinfacht in Listing \ref{lst:viewForecast} aufgeführt. Primär gibt es zwei Bediungungen. Erstens sollen nur die Dreitageverhersagewerte verwendet werden und zweitens sollen die Vorhersagewerte verwendet werden, die am nächsten bei der aktuellen Zeit liegen. Da das Vorhersageintervall 3 Stunden beträgt ist die Verhersage maximal 1.5 Stunden verschoben.

%View erstellen
\begin{lstlisting}[label=lst:viewForecast,caption=Erzeugung der VIEW für den Forecast-Vergleich, language=SQL, style=htmlcssjs]
SELECT *
FROM 'tblcompwindfinder'
WHERE
(datetime + interval 3 day) <= now() #heute vor drei Tagen
AND
abs(timediff(datetime,now())) <= 13000) #innerhalb +/- 1.5h
ORDER BY datetime DESC
LIMIT 3
\end{lstlisting}


%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Datenspeicherung}
Für die Datenspeicherung stellt Hostpoint, der Webhosting-Provider der Wetterstation, seinen Kunden eine MariaDB Version 10.1 mit dem Administrationstool phpMyAdmin zur Verfügung. MariaDB ist eine relationales Open-Source-Datenbankverwaltungssystem und basiert auf MySQL.

Die Datenbank wurde komplett neu aufgebaut. Im Folgenden werde die einzelnen Tabellen und deren Struktur erklärt.

%Für die Umstrukturierung wurde von der Methodik aus dem Artikel Grundlagen und Entwurf \cite{Datenbanken:GrundlagenUndEntwurf:VeikkoKrypczyk} gebrauch gemacht.
%Wie in Introduction to relational Databases \cite{IntroductionToRelationalDatabases:MariaDB} beschrieben wird,

\subsubsection{Aufbau und Inhalt der Datenbank}
Die Datenbank besteht aus mehreren Tabellen mit unterschiedlichem Inhalt. Die Auflistung sämtlicher Tabellen mit einer Beschreibung des Inhalts befindet sich in Tabelle\,\ref{table:dbtabellen}. Die obersten vier Tabellen werden zur Speicherung der Messwerte/Zusatzinformationen verwendet. Anschliessend kommen die drei Tabellen für die historischen Daten und zum Schluss zwei Tabelle, die für den Benachrichtungsservice und die Webcam benötigt werden.
%\Diskussionspunkt{Warum wurde keine zweite DB für Benachrichtigungsservice und Webcam erstellt? Zweite DB mit igwetter_Services?}

% Datenbank-Tabellen
\begin{table}[htbp!]
  \setlength\extrarowheight{3pt} % for a more "open" look
  \begin{tabularx}{\textwidth}{|>{\RaggedRight\hspace{0pt}}p{4.5cm}|X|}

  \hline
  %\textbf{Tabelle}
  & \bfseries Beschreibung \\

  \hline
  \textbf{tblwettertransmitter}
  & Messwerte des Wettertransmitters \\

  \hline
  \textbf{tblextsensors}
  & Messwerte der Sensoren (Bsp. Pegel) \\

  \hline
  \textbf{tblmisc}
  & Daten von Dritten (Bsp. Sturmwarnung) \\

  \hline
  \textbf{tblcompwindfinder}
  & Windvorhersagewerte von Windfinder \\

  \hline
  \hline
  \textbf{tbldatemaster}
  & Daten vom 1.1.2015 bis 31.12.2035 im Minutenabstand \\

  \hline
  \textbf{tblhistorical}
  & Messwerte zusammengefasst auf 1 Eintrag/h \\

  \hline
  \textbf{tblwaterlevelhistorical}
  & Pegelwerte von 1953 bis heute 1 Eintrag/d\\

  \hline
  \hline
  \textbf{tblnotifications}
  & Abos des Benachrichtigungsservices \\

  \hline
  \hline
  \textbf{tblqueue}
  & Warteschlange der Webcam \\

  \hline
  \end{tabularx}
  \caption{Datenbanktabellen und deren Inhalt}
  \label{table:dbtabellen} % label muss NACH caption stehen!!!!
\end{table}

\noindent
Die Tabellen haben untereinander keine Verknüpfung (Relation), sondern sind alle eigenständig. Das einzige, was sie verbindet ist der Zeitstempel des Messzeitpunkts. Es wird deshalb auf die Erstellung eines ER-Modells, wie in Datenbanken Grundlagen und Design \cite{FrankGeisler2011mitpu} beschrieben, verzichtet. In Abbildung\,\ref{img:tabellenstruktur} ist beispielhaft die Struktur der Tabelle \emph{tblextsensors} aufgeführt. Als Primärschlüssel wird jeweils der Zeitstempel des Messzeitpunkts verwendet. Da der Primärschlüssel ein UNIQUE-Wert ist, wird verhindert, dass es zwei Einträge mit dem selben Zeitstempel gibt. Das komplette relationale Datenmodell mit allen Entitäten und deren Attributen befindet sich in Anhang\,\ref{anhang:relationalesDatenbankmodell}.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/tabellenstruktur}}
	\centering
	\caption{Struktur der Tabelle \emph{tblextsensors}}
	\label{img:tabellenstruktur}
\end{figure}

%Die Normalisierung ist, wie in Datenbanken Grundlagen und Design \cite{FrankGeisler2011mitpu}, ein Prozess mit deren Hilfe die Datenbankstruktur optimiert wird und hilft dabei Datenredundanzen zu vermeiden. Da bei der Datenbank nur das Datum redundant ist, ist eine Normalisierung nicht notwendig.
%Das relationale Datenmodell unterscheidet sich in der Struktur nicht bedeutend vom ER-Modell. Der Unterschied  ist, dass die Primärschlüssel und die Datentypen festgelegt werden. Die sogenannten Schlüssel sind im relationalen Datenmodell auch ein wichtiges Merkmal. Bei zukünftigen Datenbankeinträgen sind entscheidend die Schlüssel, so kann verhindert werden, dass für einen gewissen Zeitpunkt nochmals Datensätze geschrieben werden.
%Die drei konzipierten Tabellen konnten wie gewünscht umgesetzt werden. Der Code für die Umsetzung der Tabellen, kann aus dem Anhang \ref{anhang:Datenbankcode} entnommen werden.\\


\subsubsection{Aggregation der historischen Daten}
Bei der Wetterstation fallen pro Minute rund 40 Datenpunkte an, die gespeichert werden. Pro Jahr sind dies über 21 Millionen Datenpunkte. Damit die Anzeige der historischen Messwerte nicht so viele Daten laden muss, werden die Messdaten periodisch zusammengefasst.
\newline

% Tabelle mit Minutenwerten
% Tabelle mit Tageswerten
% Wie funktioniert das Zusammenfassen der Daten -> SQL-Befehle

% \paragraph{Konzept}
\noindent
Die minütlich gespeicherten Messdaten werden einmal pro Stunde zusammengefasst und in die Tabelle mit den historischen Werten \emph{tblhistorical} geschrieben. Für die Aggregation wird die Median-Funktion verwendet um den Einfluss von Messfehlern zu reduzieren. Einmal pro Tag werden zudam die Pegeldaten des gesamten Tags gemittelt und in die Tabelle \emph{tblwaterlevelhistorical} geschrieben, wie in Abbildung\,\ref{img:historical} dargestellt.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/historical}}
	\centering
	\caption{Konezpt der Datenaggregation}
	\label{img:historical}
\end{figure}


% \paragraph{LEFT JOIN}
Das Script, welches die minütlichen Daten zu Stundendaten aggregiert greift nicht direkt auf die Messwerttabellen zu, sondern auf sogenannte VIEWs. Eine VIEW ist eine virtuelle Tabelle. Sie enthält keine Daten, sondern verweist auf die zugrundeliegenden Basistabellen. VIEWs ermöglichen es komplexere Abfragen zu vereinfachen und mehrere Tabellen über JOIN-Verknüpfungen zu einer einzigen Tabelle zusammenzufassen.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/leftjoin}}
	\centering
	\caption{Konezpt der Datenaggregation}
	\label{img:leftjoin}
\end{figure}


Die beiden VIEWs, die für die Aggregation benötigt werden beinhalten jeweils genau 60 Einträge. Einen für jede Minute der vergangenen Stunde. Damit immer für jede Minute ein Eintrag vorhanden ist, auch wenn zum Beispiel der Sensor aus irgendeinem Grund keine Messwert geliefert hat, wurde ein LEFT JOIN mit der Datemaster-Tabelle erstellt. Diese Tabelle enthält sämtliche Datum/Zeit Einträge von 2015 bis 2035 im Minutenabstand.



%Bevor sich Gedanken um die Datensicherheit gemacht werden, sollten die Bedingungen an den Speicherplatz klar sein. Während der Laufzeit werden grosse Mengen an Daten in die Datenbank geschrieben. Vor der Neukonzipierung werden täglich 1440 Datensätze gespeichert. Das bedeutet jede Minute einen Datensatz. Ein Datensatz beinhaltet 65 Einträge, die gesamte relevante Datenbank igwetter wettertest benötigt (Stand 2018-04-24) 323.2  Mb. Die Tabelle wx data, beinhaltet die Minutenwerte des Wettertransmitters, benötigt davon (Stand 2018-04-24) 311.9 Mb, daraus erfolgt das ein Datensatz ca 0.025 Mb benötigt. Für den Speicherplatz, welcher 50 Gb bietet, stellt dies kein Problem dar. Hochrechnet reicht der Platz für die kommenden 45 Jahren.


% Die Herausforderung bei der Umsetzung war es, dass die historische Tabelle, welche aus den beiden Tabellen tblwettertransmitter und tblextsensors bestehen, mittels einer Query zusammenzubringen.

% Das Problem war die Zeit. Die Daten des Wettertransmitters werden Konfigurationsbedingt, nicht auf die Minute genau, sondern 31 Sekunden später geschrieben. Bei einem LEFT JOIN, welches über die Zeit geht, werden auch die Sekunden angeschaut. Nach mehreren gescheiterten Versuchen, ist es anschliessend gelungen, eine passende Query wie in \ref{lst:LeftJoinQuery} zu entwickeln.

% Zudem wird eine historische Tabelle erstellt, diese soll, die zu stündlich aufbereiteten Daten aus den beiden Tabellen enthalten.
% Um die historische Tabelle ohne Ausfälle zu füllen wird eine Tabelle entstehen, welche alle Zeitstempel von 2015 bis 2030 beinhaltet. Welche Datenpunkte übernommen werden, kann aus dem Anhang \ref{anhang:Datenbankschema} entnommen werden.\\

% Beim Modell der historischen Daten sieht das ganze anders aus (siehe Abb. \ref{img:ER_Modell historische Daten}). Hier beinhaltet jeder Zeitstempel, den Median, sowie die Extremwerte der Daten vom Wettertransmitter und die der externen Sensoren.

% Zusätzlich sollen die Daten, welche weiterhin im Minutentakt geschrieben werden, so aufbereitet werden, dass Benutzer auf der neu erstellen historischen Webpage die Wetterdaten der vergangenen Jahre einsehen können.


% \begin{lstlisting}[label=lst:LeftJoinQuery,caption=Json Struktur, language=JavaScript, style=htmlcssjs, mathescape]
% SELECT * FROM `DateMaster`
% LEFT JOIN `tblwettertransmitter`
% ON MINUTE(dt) = MINUTE(datetime)
% WHERE ((`DateMaster`.`dt` > (now() - interval 2 hour))
% AND((`tblwettertransmitter`.`datetime` > (now() - interval 2 hour))
% AND (hour((now() - interval 1 hour)) = hour(`tblwettertransmitter`.`datetime`)))
% AND (hour((now() - interval 1 hour)) = hour(`DateMaster`.`dt`))
% AND (`DateMaster`.`dt` < now()))
% order by `DateMaster`.`dt` desc
% \end{lstlisting} */


\subsubsection{Zeitsynchronisation}
% welche Daten erhalten von wo einen Zeitstempel?
% woher erhalten diese Geräte die Zeit? Zeitserver?

\Diskussionspunkt{Grafik einfügen}


\subsubsection{Datumsformatierung}
Die Norm DIN ISO 8601\footnote{DIN ISO 8601: Informationsaustausch - Darstellung von Datum und Uhrzeit} standardisiert die Darstellung von Datum und Zeit. Das internationale Datumsformat muss entweder als \texttt{2018-07-29T15:34:30} oder aber, wie empfohlen, mit der Differenz zur Koordinierten Weltzeit (UTC) \texttt{2018-07-29T15:34:30+02:00} angegeben werden. In der Datenbank der Wetterstation wird jedoch das nichtstandartisierte Format \texttt{2018-07-29 15:34:30} mit Leerzeichen zwischen Datum und Zeit verwendet.


\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/datetime}}
	\centering
	\caption{Formatierung des Datums in der Datenbank}
	\label{img:datetime}
\end{figure}

\Diskussionspunkt{Warum kann normiertes Format nicht angewendet werden?}

\subsubsection{Umgang mit der Zeitumstellung}
Da in der Schweiz Sommer- und Winterzeit herrscht, besteht auch die Problematik der Zeitumstellung. Für die Datenbank besteht das Problem, dass die Tabellen nur einen Datumzeit enthalten dürfen. So entsteht die Problematik im Winter, da wenn die zurück gestellt wird doppelte Einträge entstehen. Wird in die historische Daten geschaut, fällt auf das diese Zeitumstellung nie berücksichtigt wurde. Zudem ist die Zeitumstellung in der Nacht, also für viele Benutzer eher uninteressant. Somit spielt es keine Rolle, dass die Daten bei der Zeitumstellung verloren gehen.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/sommerzeit}}
	\centering
	\caption{Formatierung des Datums in der Datenbank}
	\label{img:sommerzeit}
\end{figure}


%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Automatisierung der repetitiven Aufgaben (Cronjobs)}

%wiederkehrende Aufgaben – sogenannte Cronjobs – zu automatisieren.
% Der Cron-Daemon dient der zeitbasierten Ausführung von Prozessen in Unix und unixartigen Betriebssystemen wie Linux

Die Wetterstation basiert auf vielen repetitiven Aufgaben wie zum Beispiel das minütliche Einlesen der Messdaten. Linux, welches auf dem Hostpoint-Server verwendet wird, bietet mit dem Cron-Daemon ein Werkzeug um zeitbasiert Befehle beziehungsweise Skripte (Cronjobs) auszuführen. Eine Liste sämtlicher Cronjobs, die die Wetterstation verwendet ist in Tabelle \ref{table:cronjobs} dargestellt. Um einen Cronjob zu definieren muss einerseits das auszuführende Skript angegeben werden und der Zeitpunkt, zu dem es ausgeführt werden soll. Es kann zwischen Minute, Stunde und Tag gewählt werden. Ein Stern (*) bedeutet zu jeder Minute/Stunde/Tag. Die historischen Daten (\emph{historical.py}) werden beispielsweise zu jeder Stunde jeweils um 5 Minuten nach zusammengefasst. Die Windvorhersage von Windfinder (\emph{forecastWindfinder.py}) werden alle drei Stunden abgefragt (02:37, 05:37 usw.).


%Viele Funktionen werden mit Cronjobs ausgeführt. Wie von Hostpoint \cite{Hostpoint:CronjobsEinrichten} dargestellt, werden Cronjob für wiederkehrende Abläufe verwendet. Anders formuliert, kann ein Script zu einem bestimmten Zeitpunkt automatisiert ausgeführt werden. Es wird angegeben zu welchem Zeitpunkt oder in welchem Intervall das Programm ausgeführt werden soll. Der Rest übernimmt dann anschliessend der Cronjob. In diesem Fall, das Auslesen der externen Sensordaten, das erstellen der historischen Daten und das auslesen der Sturmwarnung. Auf Hostpoint kann mittels Knopfdruck ein Cronjob erstellt werden. Dabei kann auch gleich konfiguriert werden, zu welcher Zeit ein Cronjob ausgeführt werden soll (Tabelle \ref{table:cronjobs}).


% Tabelle Cronjobs
\begin{table}[htbp!]
  \setlength\extrarowheight{3pt} % for a more "open" look
  \begin{tabularx}{\textwidth}{|X|>{\RaggedRight\hspace{0pt}}p{3.5cm}|X|>{\RaggedRight\hspace{0pt}}p{5.5cm}|}

  \hline
  %\textbf{Tabelle}
  \bfseries Minute
  & \bfseries Stunde
  & \bfseries Tag
  & \bfseries Befehl/Skript \\

  %\hline
  \hline
  37
  & 2,5,8,11,14,17,20,23
  & *
  &  forecastWindfinder.py \\


  \hline
  *
  & *
  & *
  & sturmwarnung.py \\

  \hline
  *
  & *
  & *
  & externSensors.py \\

  \hline
  *
  & *
  & *
  & notifications.py \\

  \hline
  5
  & *
  & *
  & historical.py \\

  \hline
  7
  & 0
  & *
  & historicalWaterlevel.py \\


  \hline
  \end{tabularx}
  \caption{Konfiguration der Cronjobs}
  \label{table:cronjobs} % label muss NACH caption stehen!!!!
\end{table}


Die erwähnten Cronjob sind die wichtigsten, werden diese nicht durchgeführt, werden auch keinen Daten ausgelesen bzw. erstellt. Neben diesen drei Cronjobs bestehen noch zwei weitere. Diese lesen die Wettervorhersage für den Vergleich aus und schreiben die Daten in die Datenbank.

%Rechnern welche nicht durch einen Dauerbetrieb gekennzeichnet sind, kommen meist andere Varianten wie anacron zum Einsatz.





%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Datenbanksicherheit (Datenmanipulation und -verlust)}


\subsubsection{Angriffssicherheit}
Laut den OWASP\footnote{OWASP: Open Web Application Security Project} Top 10, einer Liste\footnote{ \url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}, welche die wichtigsten Sicherheitsrisiken von Web-Applikationen aufzeigt, ist SQL-injection seit Jahren auf Platz 1. SQL-Injection ist eine Methode eine Datenbankabfrage so zu manipulieren, dass der Angreifer Daten ausspähen oder verändern kann.

Bei der Wetterstation Arbon sind keine persönlichen oder sicherheitsrelevanten Daten in der Datenbank gespeichert. Somit ist diese aus Sicht eines potentiellen Angriffes eher uninteressant. Dennoch sollten die Daten hinreichend geschützt sein, um einen Datenverlust beziehungsweise eine Datenmanipulation zu verhindern.

Die Zugriffe auf die Datenbank sind so gestaltet, dass nur serverseitig darauf zugegriffen wird. Die Darstellung der Anzeigen auf der Webseiten werden über die API erstellt. Die API wiederum ist so aufgebaut, dass ein PHP-Skript auf dem Server die Daten aus der Datenbank abgreift und sie richtig formatiert. Somit kann sichergegangen werden, dass keine SQL-Injection möglich ist. Wie im Kapitel Daten der neuen Wetterstation mit Tableau \ref{kap:Tableau} erwähnt, müssen die Daten für das Tableau manuell übertragen werden. Dies bedeutet, dass für die historische Seite kein Datenbankzugriff notwendig ist. Lediglich bei der Warteschlang der Webcam und beim Benachrichtigungsservice werden Daten direkt in die Datenbank geschrieben beziehungsweise daraus gelesen. In diesem Fall werden die Eingaben maskiert wie in Listing\,\ref{lst:maskierung} dargestellt.

\begin{lstlisting}[label=lst:maskierung,caption=Maskierung von Datenbank-Eingaben, language=PHP, style=PHP]
$threshold = mysql_escape_string($_POST['threshold']);
\end{lstlisting}


\subsubsection{DB-Nutzer Konzept}
\Diskussionspunkt{welche Nutzer gibt es und welche Rechte haben sie -> theoretisch erklären}

\subsubsection{Backup}
Um die Datenbank gegen einen allfälligen Datenverlust zu sichern, ist ein Backup sinnvoll. Da alle Daten in der DB gleich relevant sind, sollten auch alle im Backup vorhanden sein. Dabei muss aber entschieden werden, ob ein tägliches Backup Sinn machen würde. Da die Wetterstation von einem Verein betrieben wird, ist es wichtig den Aufwand mit dem Ertrag zu vergleichen. Zusätzlich sollte das Backup nicht auf dem Server des Providers gespeichert werden, sollte etwas mit dem Server nicht in Ordnung sein, sind diese Daten auch weg. Deswegen ist es wichtig ein 'externes' Backup zu erstellen. Hostpoint bietet für das Backup verschiedene zwei Varianten: Backup mittels Cronjob und Backup auf Knopfdruck. Um den Aufwand klein zu halten, wird empfohlen ein monatliches Backup mit der Backup Funktion auf Knopfdruck zu erstellen und dieses auf einer Festplatte zu speichern (Abbildung \ref{img:backup}). Sollte trotzdem mal das Backup nicht funktionierten oder vergessen gegangen sein, kann auf den Hostpoint-Service zurück gegriffen werden. Hostpoint erstellt selber ein tägliches Backup, welches für 100 Franken wieder eingespielt werden kann. Somit können die Kosten für beispielsweise einigen Cloudaccount gespart werden.

\begin{figure}[htbp!]
  \fbox{\includegraphics[width=\textwidth-2\fboxsep-2\fboxrule]{img/backup}}
	\centering
	\caption{Backup auf Knopfdruck von Hostpoint}
	\label{img:backup}
\end{figure}


%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Datenarchivierung und Speicherbedarf}
In der Datenarchivierung werden die historischen Daten aufbereitet und komprimiert. Dafür ist wird von der historischen Tabelle gebrauch gemacht. Mittels einem Cronjob werden die Minuten Daten komprimiert. Anschliessend bestehen zwei Varianten:

\begin{itemize*}
\item \textbf{Variante 1}\\
Die Daten aus den beiden Minutentabellen werden gelöscht, stehen somit nicht zu weiteren Zwecken zur Verfügung.
\item \textbf{Variante 2}\\
Die Daten aus den beiden Minutentabellen werden nicht gelöscht und können für spätere Anwendungen verwendet werden.
\end{itemize*}

Da beim Server der Speicherplatz kein ausschlaggebender Punkt ist, wurde für die zweite Variante entschieden.



%% ############################################################################
%% Unterkapitel
%% ############################################################################
\subsection{Funktionsüberwachung mit Mail-Service}\label{kap:Funktionsüberwachung}
Um diese Funktionen zu erstellen wird Gebrauch vom try, except Verfahren in Python gemacht. Zu Beginn wird der Code im try ausgeführt, tritt keine exception auf, wird das except übersprungen und der anschliessende Code ausgeführt. Tritt aber während dem try eine exception auf, wird der Code unterbrochen und der im except weitergeführt. Anschliessend wird der Code nach dem Exception Handling ausgeführt.\cite{ThePythonTutorial8.ErrorsAndExceptions:Python}

Um die Funktion der Programme/Skripte zu überwachen, erzeugen folgende Funktionen bei einem Fehler (exeption) eine Meldung:

\begin{itemize*}
\item Einlesen der Sensordaten (Wassertemperatur, Pegel, Strahlung)
\item Einlesen Wettertransmitter-Daten
\item Erstellung der stündlichen und täglichen historischen Daten
\item Einlesen der Sturmwarn- und Windprognosedaten
\item Benachrichtiungsservice
\end{itemize*}

Die aufgezählten Funktionen werden alle bis auf das Einlesen der Wettertransmitter Daten über einen Cronjob ausgeführt. Hostpoint bietet die Möglichkeit, dass sämtliche Textausgaben (print-Funktion) eines Cronjobs an eine bestimmte Mailadresse gesendet werden (Listing \ref{lst:printfunction}). Der Service wurde so konfiguriert, dass die Fehlermeldungen an die Mailadresse \emph{cronjob@wetter-arbon.ch}. Der Posteingang kann dann an die entsprechenden Personen weitergeleitet werden.

\begin{lstlisting}[label=lst:printfunction,caption=Beispiel für print Funktion, language=Python, style=py]
except Exception as e:
    print "Es ist ein Problem mit der Sonnenstrahlungs-Abfrage aufgetaucht: "
    print e
\end{lstlisting}

Für das Einlesen der externen Sensordaten sieht der Mailservice folgendermassen aus. Kann einer der Webservices vom Web-IO nicht erreicht werden, wird die folgende Mail generiert:

\begin{quote}
Es ist ein Problem mit (der Temperatur, dem Pegel, dem Strahlungssensor) aufgetreten. Exception: ...\\
\end{quote}

Je nach Sensor wird dieser genannt und das Problem welches aufgetreten ist. Beim Auslesen des Wettertransmitters ist diese Möglichkeit nicht direkt anwendbar. Hier wird beim erstellen der historischen Daten kontrolliert ob alle 60 Einträge der letzen Stunde vorhanden sind. Ist dies nicht der Fall, würde es bedeuten, dass das WeatherDisplay abgestürzt ist und neu gestartet werden muss. Die Meldung sieht folgendermassen aus:\\

\begin{quote}
Bitte starte das WeatherDisplay neu, es wurden nur (Anzahl Datensätze) Daten geschrieben.
\end{quote}

Auch beim schreiben in die historische Datenbank können Ausnahmen auftauchen. Ist dies der Fall wird folgende Meldung generiert:\\

\begin{quote}
Die historischen Daten können nicht geschrieben werden, es besteht folgendes Problem (Exception).
\end{quote}
